{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40525e36-da62-4830-921b-6719fa207606",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found files: ['../data\\\\amazon_india_2015.csv', '../data\\\\amazon_india_2016.csv', '../data\\\\amazon_india_2017.csv', '../data\\\\amazon_india_2018.csv', '../data\\\\amazon_india_2019.csv', '../data\\\\amazon_india_2020.csv', '../data\\\\amazon_india_2021.csv', '../data\\\\amazon_india_2022.csv', '../data\\\\amazon_india_2023.csv', '../data\\\\amazon_india_2024.csv', '../data\\\\amazon_india_2025.csv']\n",
      "Reading: ../data\\amazon_india_2015.csv\n",
      "Reading: ../data\\amazon_india_2016.csv\n",
      "Reading: ../data\\amazon_india_2017.csv\n",
      "Reading: ../data\\amazon_india_2018.csv\n",
      "Reading: ../data\\amazon_india_2019.csv\n",
      "Reading: ../data\\amazon_india_2020.csv\n",
      "Reading: ../data\\amazon_india_2021.csv\n",
      "Reading: ../data\\amazon_india_2022.csv\n",
      "Reading: ../data\\amazon_india_2023.csv\n",
      "Reading: ../data\\amazon_india_2024.csv\n",
      "Reading: ../data\\amazon_india_2025.csv\n",
      "Combined dataset shape: (1127609, 34)\n",
      "Combined file saved to outputs/amazon_india_2015_2025_raw.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "data_path = \"../data\"     \n",
    "output_path = \"../outputs\"\n",
    "\n",
    "files = sorted(glob.glob(os.path.join(data_path, \"amazon_india_20*.csv\")))\n",
    "print(\"Found files:\", files)\n",
    "\n",
    "dfs = []\n",
    "for f in files:\n",
    "    print(\"Reading:\", f)\n",
    "    dfs.append(pd.read_csv(f, low_memory=False))\n",
    "    \n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Combined dataset shape:\", df.shape)\n",
    "\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "df.to_csv(os.path.join(output_path, \"amazon_india_2015_2025_raw.csv\"), index=False)\n",
    "print(\"Combined file saved to outputs/amazon_india_2015_2025_raw.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8b2cd34-4db6-4311-996a-d1a0ffb83e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial rows: 1127609\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>order_date</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_name</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>brand</th>\n",
       "      <th>original_price_inr</th>\n",
       "      <th>discount_percent</th>\n",
       "      <th>...</th>\n",
       "      <th>is_festival_sale</th>\n",
       "      <th>festival_name</th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>return_status</th>\n",
       "      <th>order_month</th>\n",
       "      <th>order_year</th>\n",
       "      <th>order_quarter</th>\n",
       "      <th>product_weight_kg</th>\n",
       "      <th>is_prime_eligible</th>\n",
       "      <th>product_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TXN_2015_00000001</td>\n",
       "      <td>2015-01-25</td>\n",
       "      <td>CUST_2015_00003884</td>\n",
       "      <td>PROD_000021</td>\n",
       "      <td>Samsung Galaxy S6 16GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>123614.29</td>\n",
       "      <td>27.91</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Republic Day Sale</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.19</td>\n",
       "      <td>True</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TXN_2015_00000002</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td>CUST_2015_00011709</td>\n",
       "      <td>PROD_000055</td>\n",
       "      <td>OnePlus OnePlus 2 16GB White</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>OnePlus</td>\n",
       "      <td>54731.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.20</td>\n",
       "      <td>True</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TXN_2015_00000003</td>\n",
       "      <td>2015-01-24</td>\n",
       "      <td>CUST_2015_00004782</td>\n",
       "      <td>PROD_000039</td>\n",
       "      <td>Samsung Galaxy Note 5 64GB Black</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>Smartphones</td>\n",
       "      <td>Samsung</td>\n",
       "      <td>97644.25</td>\n",
       "      <td>46.93</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>Republic Day Sale</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Delivered</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>0.17</td>\n",
       "      <td>True</td>\n",
       "      <td>3.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      transaction_id  order_date         customer_id   product_id  \\\n",
       "0  TXN_2015_00000001  2015-01-25  CUST_2015_00003884  PROD_000021   \n",
       "1  TXN_2015_00000002  2015-01-05  CUST_2015_00011709  PROD_000055   \n",
       "2  TXN_2015_00000003  2015-01-24  CUST_2015_00004782  PROD_000039   \n",
       "\n",
       "                       product_name     category  subcategory    brand  \\\n",
       "0      Samsung Galaxy S6 16GB Black  Electronics  Smartphones  Samsung   \n",
       "1      OnePlus OnePlus 2 16GB White  Electronics  Smartphones  OnePlus   \n",
       "2  Samsung Galaxy Note 5 64GB Black  Electronics  Smartphones  Samsung   \n",
       "\n",
       "  original_price_inr  discount_percent  ...  is_festival_sale  \\\n",
       "0          123614.29             27.91  ...              True   \n",
       "1           54731.86              0.00  ...             False   \n",
       "2           97644.25             46.93  ...              True   \n",
       "\n",
       "       festival_name  customer_rating  return_status  order_month order_year  \\\n",
       "0  Republic Day Sale              5.0      Delivered            1       2015   \n",
       "1                NaN              4.5      Delivered            1       2015   \n",
       "2  Republic Day Sale              NaN      Delivered            1       2015   \n",
       "\n",
       "  order_quarter product_weight_kg is_prime_eligible product_rating  \n",
       "0             1              0.19              True            4.7  \n",
       "1             1              0.20              True            4.1  \n",
       "2             1              0.17              True            3.3  \n",
       "\n",
       "[3 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "from cleaning_utils import * \n",
    "df = pd.read_csv(\"../outputs/amazon_india_2015_2025_raw.csv\", low_memory=False)\n",
    "print(\"Initial rows:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c04c640e-0383-466b-8d0d-65d650155a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All cleaning functions applied!\n"
     ]
    }
   ],
   "source": [
    "# Dates\n",
    "df = clean_order_date(df, 'order_date')\n",
    "\n",
    "# Price\n",
    "df = clean_original_price(df, 'original_price_inr')\n",
    "\n",
    "# Ratings\n",
    "df = clean_ratings(df, 'product_rating')\n",
    "\n",
    "# City names\n",
    "df = clean_customer_city(df, 'customer_city')\n",
    "\n",
    "# Boolean columns\n",
    "df = clean_boolean_cols(df, ['is_prime_member','is_prime_eligible','is_festival_sale'])\n",
    "\n",
    "# Categories\n",
    "df = clean_category(df, 'category')\n",
    "\n",
    "# Delivery days\n",
    "df = clean_delivery_days(df, 'delivery_days')\n",
    "\n",
    "# Duplicates\n",
    "df = mark_duplicates(df)\n",
    "\n",
    "# Outlier correction (depends on category_clean)\n",
    "df = correct_price_outliers(df, price_col='original_price_inr_clean')\n",
    "\n",
    "# Payment methods\n",
    "df = clean_payment_method(df, 'payment_method')\n",
    "\n",
    "print(\"All cleaning functions applied!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81fe5b11-3fb0-4708-8614-e022309780ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_date</th>\n",
       "      <th>order_date_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>574576</th>\n",
       "      <td>2021-05-02</td>\n",
       "      <td>2021-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766207</th>\n",
       "      <td>2022-10-29</td>\n",
       "      <td>2022-10-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044537</th>\n",
       "      <td>21/12/2024</td>\n",
       "      <td>2024-12-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>331862</th>\n",
       "      <td>2019-08-28</td>\n",
       "      <td>2019-08-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>832048</th>\n",
       "      <td>2023-04-14</td>\n",
       "      <td>2023-04-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         order_date order_date_clean\n",
       "574576   2021-05-02       2021-05-02\n",
       "766207   2022-10-29       2022-10-29\n",
       "1044537  21/12/2024       2024-12-21\n",
       "331862   2019-08-28       2019-08-28\n",
       "832048   2023-04-14       2023-04-14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['order_date', 'order_date_clean']].sample(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1928bbb8-7862-4b97-816a-9549ecd11a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_price_inr</th>\n",
       "      <th>original_price_inr_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>600513</th>\n",
       "      <td>125574.02</td>\n",
       "      <td>125574.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477895</th>\n",
       "      <td>98321.19</td>\n",
       "      <td>98321.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096616</th>\n",
       "      <td>27725.18</td>\n",
       "      <td>27725.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922307</th>\n",
       "      <td>181191.8</td>\n",
       "      <td>181191.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>944163</th>\n",
       "      <td>111414.43</td>\n",
       "      <td>111414.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        original_price_inr  original_price_inr_clean\n",
       "600513           125574.02                 125574.02\n",
       "477895            98321.19                  98321.19\n",
       "1096616           27725.18                  27725.18\n",
       "922307            181191.8                 181191.80\n",
       "944163           111414.43                 111414.43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['original_price_inr', 'original_price_inr_clean']].sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f862b22d-5a58-4387-a223-6d9c595f37d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product_rating</th>\n",
       "      <th>product_rating_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>590767</th>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462574</th>\n",
       "      <td>4.4</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486099</th>\n",
       "      <td>4.6</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374731</th>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759510</th>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        product_rating  product_rating_clean\n",
       "590767             4.4                   4.4\n",
       "462574             4.4                   4.4\n",
       "486099             4.6                   4.6\n",
       "374731             3.5                   3.5\n",
       "759510             4.5                   4.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['product_rating', 'product_rating_clean']].sample(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c504144-d150-47e1-975b-29260cf3f1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns replaced. Current shape: (1127609, 41)\n"
     ]
    }
   ],
   "source": [
    "cols_to_replace = {\n",
    "    'order_date_clean': 'order_date',\n",
    "    'original_price_inr_clean': 'original_price_inr',\n",
    "    'product_rating_clean': 'product_rating',\n",
    "    'customer_city_clean': 'customer_city',\n",
    "    'category_clean': 'category',\n",
    "    'delivery_days_clean': 'delivery_days',\n",
    "    'payment_method_clean': 'payment_method'\n",
    "}\n",
    "for clean_col, orig_col in cols_to_replace.items():\n",
    "    if clean_col in df.columns:\n",
    "        df[orig_col] = df[clean_col]\n",
    "        df.drop(columns=[clean_col], inplace=True, errors='ignore')\n",
    "\n",
    "print(\"Columns replaced. Current shape:\", df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9a62320-d835-446f-9422-858b73f150f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to outputs folder!\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../outputs\", exist_ok=True)\n",
    "df.to_csv(\"../outputs/amazon_cleaned.csv\", index=False)\n",
    "df.to_parquet(\"../outputs/amazon_cleaned.parquet\", index=False)\n",
    "print(\"Cleaned dataset saved to outputs folder!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "643732b5-80ed-4f1c-9470-7623fa45a90e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 1127609\n",
      "Columns: 41\n",
      "\n",
      "Missing values per column (top 10):\n",
      "festival_name         777736\n",
      "customer_rating       341696\n",
      "customer_age_group    135315\n",
      "delivery_charges       90201\n",
      "delivery_days           2317\n",
      "order_date                 0\n",
      "customer_id                0\n",
      "product_id                 0\n",
      "transaction_id             0\n",
      "original_price_inr         0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Total rows:\", len(df))\n",
    "print(\"Columns:\", len(df.columns))\n",
    "print(\"\\nMissing values per column (top 10):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(10))\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "76dbe109-247d-4770-b5c0-3baf5e1910b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns replaced. Current shape: (1127609, 41)\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns replaced. Current shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a6f18961-0e83-4663-8921-08e49e56e633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset successfully created.\n",
      "Shape: (1127609, 41)\n",
      "\n",
      "Missing values per column (top 10):\n",
      "festival_name         777736\n",
      "customer_rating       341696\n",
      "customer_age_group    135315\n",
      "delivery_charges       90201\n",
      "delivery_days           2317\n",
      "order_date                 0\n",
      "customer_id                0\n",
      "product_id                 0\n",
      "transaction_id             0\n",
      "original_price_inr         0\n",
      "dtype: int64\n",
      "\n",
      "Duplicate rows: 0\n",
      "\n",
      "Price range: -300102.68 â†’ 33371693.0\n",
      "Rating range: 3.0 â†’ 4.8\n",
      "\n",
      "Unique payment methods: ['COD' 'Debit Card' 'Credit Card' 'Netbanking' 'UPI' 'Wallet' 'Bnpl']\n",
      "Unique categories: ['Electronics']\n",
      "Unique cities: ['Mumbai' 'Allahabad' 'Kolkata' 'Ludhiana' 'New Delhi' 'Lucknow' 'Jaipur'\n",
      " 'Bhubaneswar' 'Ahmedabad' 'Bengaluru']\n"
     ]
    }
   ],
   "source": [
    "print(\"Cleaned dataset successfully created.\")\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nMissing values per column (top 10):\")\n",
    "print(df.isna().sum().sort_values(ascending=False).head(10))\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "print(\"\\nPrice range:\", df['original_price_inr'].min(), \"â†’\", df['original_price_inr'].max())\n",
    "print(\"Rating range:\", df['product_rating'].min(), \"â†’\", df['product_rating'].max())\n",
    "\n",
    "print(\"\\nUnique payment methods:\", df['payment_method'].dropna().unique()[:10])\n",
    "print(\"Unique categories:\", df['category'].dropna().unique()[:10])\n",
    "print(\"Unique cities:\", df['customer_city'].dropna().unique()[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a05138b-f397-48ff-8b6e-00d6b5d6f1bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'â€”' (U+2014) (3868511953.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mAdvanced Data Cleaning â€” Q1 to Q10\u001b[39m\n                           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid character 'â€”' (U+2014)\n"
     ]
    }
   ],
   "source": [
    "Advanced Data Cleaning â€” Q1 to Q10\n",
    "====================================\n",
    "\n",
    "Q1. Clean and standardize all order dates\n",
    "Question: Your dataset contains order_date in multiple formats â€” 'DD/MM/YYYY', 'DD-MM-YY', 'YYYY-MM-DD', and invalid entries like '32/13/2020'. Clean and standardize all dates to 'YYYY-MM-DD' format, handling invalid dates appropriately.\n",
    "\n",
    "Problem: The dataset includes inconsistent date formats and some impossible values. These make time-series analysis (like revenue by year or month) unreliable.\n",
    "\n",
    "Approach: Used the function:\n",
    "    \n",
    "df = clean_order_date(df, 'order_date')\n",
    "    \n",
    "It applies parse_date_safe() which tries multiple date formats and uses dateutil.parser as a fallback. Invalid or unreadable dates are converted to NaT.\n",
    "Result: All dates are now in consistent YYYY-MM-DD format. Invalid or corrupted entries are safely handled as missing (NaT).\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    "    \n",
    "Q2. Clean and standardize the original_price_inr column\n",
    "\n",
    "Question: original_price_inr contains numeric values, text with â‚¹ symbols, comma separators (â‚¹1,25,000), and entries like \"Price on Request\". Clean this column to contain only numeric values in Indian Rupees.\n",
    "\n",
    "Problem: The column mixes text, currency symbols, and non-numeric entries which prevent correct numeric computations.\n",
    "\n",
    "Approach: Used:\n",
    "df = clean_original_price(df, 'original_price_inr')\n",
    "\n",
    "The function removes currency symbols (â‚¹), commas, and non-numeric text. Entries like \"Price on Request\" are replaced with NaN.\n",
    "\n",
    "Result: All prices are stored as clean numeric values in INR, ready for statistical or financial analysis.\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    " \n",
    "Q3. Standardize customer ratings\n",
    "\n",
    "Question: Customer ratings appear as '5.0', '4 stars', '3/5', '2.5/5.0', and missing values. Standardize all ratings to a numeric 1.0â€“5.0 scale.\n",
    "\n",
    "Problem: Mixed rating formats and text prevent accurate averaging and comparison.\n",
    "\n",
    "Approach: Used:\n",
    "df = clean_ratings(df, 'product_rating')\n",
    "Extracts numeric parts from each string, converts percentages (like '80%') to a 1â€“5 scale, and caps all values at 5. Missing values remain NaN.\n",
    "\n",
    "Result: All ratings are standardized numeric floats between 1.0 and 5.0.\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    " \n",
    "Q4. Standardize city names\n",
    "\n",
    "Question: The customer_city column has inconsistent naming: 'Bangalore/Bengaluru', 'Mumbai/Bombay', 'Delhi/New Delhi', along with spelling errors and case variations.\n",
    "\n",
    "Problem: Multiple variations of the same city prevent grouping or geographic analysis.\n",
    "\n",
    "Approach: Used:\n",
    "df = clean_customer_city(df, 'customer_city')\n",
    "\n",
    "Applies a city mapping (CITY_MAP) to merge variants like 'Bombay' â†’ 'Mumbai', 'Bangalore' â†’ 'Bengaluru', 'Delhi' â†’ 'New Delhi'. Also fixes casing and typos.\n",
    "\n",
    "Result: All city names are standardized to canonical forms (e.g., Bengaluru, Mumbai, New Delhi).\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    " \n",
    "Q5. Convert Boolean columns to consistent format\n",
    "\n",
    "Question: Boolean columns (is_prime_member, is_prime_eligible, is_festival_sale) contain mixed values like True/False, Yes/No, 1/0, Y/N, and missing entries.\n",
    "\n",
    "Problem: Inconsistent boolean representation makes filtering and logic operations fail.\n",
    "\n",
    "Approach: Used:\n",
    "\n",
    "df = clean_boolean_cols(df, ['is_prime_member', 'is_prime_eligible', 'is_festival_sale'])\n",
    "\n",
    "Converts all truthy/falsey values to True or False (Python boolean type).\n",
    "\n",
    "Result: All three boolean columns are clean and consistent (True or False), with missing entries preserved as NaN.\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    " \n",
    "Q6. Standardize product categories\n",
    "\n",
    "Question: Product categories vary as 'Electronics/Electronic/ELECTRONICS/Electronics & Accessories'.\n",
    "\n",
    "Problem: Different naming conventions and letter casing cause duplicate category entries.\n",
    "\n",
    "Approach: Used:\n",
    "df = clean_category(df, 'category')\n",
    "\n",
    "Normalizes text (lowercase, replaces symbols, removes special characters). Then maps similar words to a common category name such as Electronics, Fashion, Home & Kitchen, etc.\n",
    "\n",
    "Result: All product categories follow a consistent naming convention, allowing accurate grouping and comparison.\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    " \n",
    "Q7. Clean the delivery_days column\n",
    "\n",
    "Question: delivery_days has text like 'Same Day', '1-2 days', and unrealistic values like 50 or negative numbers.\n",
    "\n",
    "Problem: Delivery time analysis becomes meaningless if entries arenâ€™t numeric or valid.\n",
    "\n",
    "Approach: Used:\n",
    "df = clean_delivery_days(df, 'delivery_days')\n",
    "\n",
    "Converts text to numeric (mean of ranges), 'Same Day' â†’ 0, and removes invalid or unrealistic values (negative or > 30).\n",
    "\n",
    "Result: All delivery_days values are numeric and realistic.\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    " \n",
    "Q8. Identify and handle duplicate transactions\n",
    "\n",
    "Question: Some transactions are exact duplicates of the same customer, product, date, and amount â€” some are genuine bulk orders, others are data errors.\n",
    "\n",
    "Problem: Duplicate records distort revenue and customer counts.\n",
    "\n",
    "Approach: Used:\n",
    " df = mark_duplicates(df)\n",
    "\n",
    "Creates a composite key combining customer_id, product_id, order_date, and final_amount_inr. Marks potential duplicates with is_duplicate = True.\n",
    "\n",
    "Result: Duplicate entries are identified for manual review or removal as needed.\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    " \n",
    "Q9. Correct outlier prices\n",
    "\n",
    "Question: Some products show prices 100Ã— higher than expected due to misplaced decimal points.\n",
    "\n",
    "Problem: Extreme price outliers distort average price and revenue calculations.\n",
    "\n",
    "Approach: Used:\n",
    "df = correct_price_outliers(df, price_col='original_price_inr_clean')\n",
    "\n",
    "Compares each price with the category median. If the price is 20â€“100Ã— higher, divides by 10 or 100 accordingly.\n",
    "\n",
    "Result:Outlier prices corrected to realistic levels based on category norms.\n",
    "    \n",
    "========================================================================\n",
    "=========================================================================  \n",
    " \n",
    "Q10. Standardize payment method names\n",
    "\n",
    "Question: Payment methods have inconsistent naming: 'UPI/PhonePe/GooglePay', 'Credit Card/CREDIT_CARD/CC', 'Cash on Delivery/COD/C.O.D'.\n",
    "\n",
    "Problem: Variations make it difficult to analyze payment preferences.\n",
    "\n",
    "Approach: Used:\n",
    "df = clean_payment_method(df, 'payment_method')\n",
    "\n",
    "Maps similar names into six standard groups:\n",
    "UPI, Credit Card, Debit Card, Netbanking, COD, Wallet.\n",
    "\n",
    "Result:Payment methods are standardized across all transactions, enabling clean analysis of payment trends.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4875dcf1-aed1-44bb-a6d8-127948caea8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
